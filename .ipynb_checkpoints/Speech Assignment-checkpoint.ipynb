{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave, os, glob, csv, sys, pathlib, math, gc\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy import save, load, savez\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "import h5py\n",
    "# import cv2\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "dir_path = os.path.abspath('')\n",
    "os.chdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Shaun\\\\Documents\\\\MSc AI\\\\Semester 2\\\\ANLP\\\\Speech\\\\Assignment'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have a look at the files in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain list of dataset, labels and speakers\n",
    "this_directory = os.getcwd()\n",
    "filelist = []\n",
    "filepathlist = []\n",
    "ids = []\n",
    "\n",
    "def get_file_paths(dirname):\n",
    "    file_paths = []\n",
    "    subdir_paths = []\n",
    "    for root, directories, files in os.walk(dirname):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join(root, filename)\n",
    "            file_paths.append(filepath)\n",
    "    return file_paths    \n",
    "\n",
    "def get_dataset_list():\n",
    "    files = get_file_paths(this_directory)                 \n",
    "    for file in files:                              \n",
    "        (filepath, ext) = os.path.splitext(file)    \n",
    "        file_name = os.path.basename(file)\n",
    "        sub_directory = os.path.dirname(file)\n",
    "        sub_directory = sub_directory.split('/')[-1]\n",
    "        if ext == '.wav':                           \n",
    "            filelist.append(file_name)\n",
    "            filepathlist.append(sub_directory)\n",
    "    for file in filelist:\n",
    "        ids.append(file[0:7])\n",
    "    dataset_list = list(zip(filelist, filepathlist, ids))\n",
    "    return dataset_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_list = get_dataset_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at training + test + validation sizes\n",
    "training_size = round(0.7*len(dataset_list))\n",
    "validation_size = round(0.1*len(dataset_list))\n",
    "test_size = len(dataset_list) - (training_size + validation_size)\n",
    "\n",
    "#Sanity Check\n",
    "print(training_size + validation_size + test_size)\n",
    "print(len(dataset_list))\n",
    "\n",
    "#Convert to dataframe, create labels list\n",
    "dataset_df = pd.DataFrame(dataset_list, columns = (\"FileName\", \"Label\", \"Speaker\"))\n",
    "labels = set(filepathlist)\n",
    "print(labels)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Dataset for Imbalance Check\n",
    "f, ax = plt.subplots(figsize=(15,6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.countplot(x=\"Label\",\n",
    "data=dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at unusable recordings shorter than 1 second and removing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_of_recordings=[]\n",
    "unusable_files = []\n",
    "waves = [file for file in dataset_df[\"FileName\"]]\n",
    "for index, row in dataset_df.iterrows():\n",
    "    sample_rate, samples = wavfile.read(os.getcwd()+ \"/\" + row['Label'] + \"/\" + row['FileName'])\n",
    "    duration_of_recordings.append(float(len(samples)/sample_rate))\n",
    "    if samples.shape[0] < sample_rate:\n",
    "        unusable_files.append(row['Label'] + \"/\" + row['FileName'])\n",
    "        dataset_df.drop(index, inplace=True)\n",
    "    gc.collect\n",
    "\n",
    "plt.hist(np.array(duration_of_recordings), range=(0.6,1.3))\n",
    "plt.xlabel('Duration in seconds')\n",
    "plt.ylabel('Quantity of files')\n",
    "plt.savefig('duration.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Dataset for Imbalance Check after dropping unusable files\n",
    "f, ax = plt.subplots(figsize=(15,6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "imb = sns.countplot(x=\"Label\",\n",
    "                    data=dataset_df,\n",
    "                    palette=\"Greens_d\")\n",
    "plt.savefig('dataimb.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into separate dataframes\n",
    "grouped_df = dataset_df.groupby(dataset_df.Label)\n",
    "\n",
    "house_df = grouped_df.get_group(\"house\")\n",
    "cat_df = grouped_df.get_group(\"cat\")\n",
    "bird_df = grouped_df.get_group(\"bird\")\n",
    "left_df = grouped_df.get_group(\"left\")\n",
    "off_df = grouped_df.get_group(\"off\")\n",
    "dog_df = grouped_df.get_group(\"dog\")\n",
    "marvin_df = grouped_df.get_group(\"marvin\")\n",
    "backward_df = grouped_df.get_group(\"backward\")\n",
    "go_df = grouped_df.get_group(\"go\")\n",
    "visual_df = grouped_df.get_group(\"visual\")\n",
    "\n",
    "df_sublist = []\n",
    "df_train_sublist = []\n",
    "df_testval_sublist = []\n",
    "for label in labels:\n",
    "    df_sublist.append((\"{}_df\").format(label))\n",
    "    df_train_sublist.append((\"{}_df_train\").format(label))\n",
    "    df_testval_sublist.append((\"{}_df_testval\").format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sublist)\n",
    "print(df_train_sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates_to_training_set(df):\n",
    "    if len(df[df.duplicated(\"Speaker\", keep=False)]) <= (0.7* len(df)):\n",
    "        print(\"{:.2%}\".format(len(df[df.duplicated(\"Speaker\", keep=False)])/len(df)))\n",
    "    else: \n",
    "        print(\"{:.2%}\".format(len(df[df.duplicated(\"Speaker\", keep=False)])/len(df)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing files for training set and checking the 70% split for data balance\n",
    "house_df_train =check_duplicates_to_training_set(house_df)\n",
    "cat_df_train =check_duplicates_to_training_set(cat_df)\n",
    "bird_df_train =check_duplicates_to_training_set(bird_df)\n",
    "left_df_train =check_duplicates_to_training_set(left_df)\n",
    "off_df_train =check_duplicates_to_training_set(off_df)\n",
    "dog_df_train =check_duplicates_to_training_set(dog_df)\n",
    "marvin_df_train =check_duplicates_to_training_set(marvin_df)\n",
    "backward_df_train = check_duplicates_to_training_set(backward_df)\n",
    "go_df_train =check_duplicates_to_training_set(go_df)\n",
    "visual_df_train =check_duplicates_to_training_set(visual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many recordings have others by the same speaker\n",
    "num_of_dupes = 0\n",
    "for df in df_sublist:\n",
    "    print(len(eval(df)[eval(df).duplicated(\"Speaker\", keep=False)]))\n",
    "    num_of_dupes += (len(eval(df)[eval(df).duplicated(\"Speaker\", keep=False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:.2%}\".format(num_of_dupes/len(dataset_list)))\n",
    "#Since this is below 70% we could proceed to add all the data to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_duplicates_to_training_set(df):\n",
    "    return df[df.duplicated(\"Speaker\", keep=False)], df.drop_duplicates(subset=\"Speaker\", keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populating training and test/val dataframes\n",
    "house_df_train, house_df_testval = add_duplicates_to_training_set(house_df)\n",
    "cat_df_train,cat_df_testval = add_duplicates_to_training_set(cat_df)\n",
    "bird_df_train, bird_df_testval = add_duplicates_to_training_set(bird_df)\n",
    "left_df_train, left_df_testval = add_duplicates_to_training_set(left_df)\n",
    "off_df_train, off_df_testval = add_duplicates_to_training_set(off_df)\n",
    "dog_df_train, dog_df_testval = add_duplicates_to_training_set(dog_df)\n",
    "marvin_df_train, marvin_df_testval = add_duplicates_to_training_set(marvin_df)\n",
    "backward_df_train, backward_df_testval = add_duplicates_to_training_set(backward_df)\n",
    "go_df_train, go_df_testval = add_duplicates_to_training_set(go_df)\n",
    "visual_df_train, visual_df_testval = add_duplicates_to_training_set(visual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack test_validation dataframe\n",
    "test_val_array = np.vstack(eval(df).values for df in df_testval_sublist)\n",
    "test_val_array = test_val_array[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Test and Validation Sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(test_val_array[:,:-1], test_val_array[:,-1], test_size = 0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating test and validation sets\n",
    "val_set = np.column_stack((X_val,y_val))\n",
    "test_set = np.column_stack((X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_speech_mfcc(raw_train_data, label):\n",
    "    label_vector = []\n",
    "    dirname = os.getcwd()\n",
    "    for index, row in raw_train_data.iterrows():\n",
    "        (rate,sig) = wavfile.read(dirname + \"/\" + row['Label'] + \"/\" + row['FileName'])\n",
    "        mfcc_feat = mfcc(sig,rate,nfft=1024)\n",
    "        label_vector.append(mfcc_feat)\n",
    "        gc.collect\n",
    "    label_array = np.concatenate(label_vector, axis=0)\n",
    "    b = [label for i in range(label_array.shape[0])]\n",
    "    label_array = np.column_stack((label_array, b))\n",
    "#     print(raw_train_data.head(),label)\n",
    "#     print(label_array.shape)\n",
    "    return label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_Val Set MFCC\n",
    "mfcc_df_testval = np.empty((0,14))\n",
    "\n",
    "for df, label in zip(df_testval_sublist, labels):\n",
    "    mfcc_df_testval = np.append(mfcc_df_testval, python_speech_mfcc(eval(df), label), axis=0)\n",
    "    gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Set MFCC\n",
    "mfcc_df_train = np.empty((0,14))\n",
    "\n",
    "for df, label in zip(df_train_sublist, labels):\n",
    "    mfcc_df_train = np.append(mfcc_df_train, python_speech_mfcc(eval(df), label), axis=0)\n",
    "    gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to numpy array files\n",
    "save('mfcc_testval.npy', mfcc_df_testval)\n",
    "save('mfcc_train.npy', mfcc_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to zipped numpy array file\n",
    "mfcc_df_testval = load('mfcc_testval_clean.npz')\n",
    "mfcc_df_train = load('mfcc_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Test and Val Sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(mfcc_df_testval['arr_0'][:,:-1], mfcc_df_testval['arr_0'][:,-1], test_size = 0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting X-train and y-train\n",
    "X_train = mfcc_df_train[:, :-1]\n",
    "y_train = mfcc_df_train[:, -1]\n",
    "\n",
    "# Shuffling the training set\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 4 1 ... 8 5 2]\n",
      "[8 5 7 ... 8 2 3]\n",
      "[5 3 9 ... 1 9 3]\n"
     ]
    }
   ],
   "source": [
    "# #Encoding the labels\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "lenc = LabelEncoder()\n",
    "y_train = lenc.fit_transform(y_train)\n",
    "y_val = lenc.fit_transform(y_val)\n",
    "y_test = lenc.fit_transform(y_test)\n",
    "print(y_train)\n",
    "print(y_val)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # One Hot Encoding cause multiclass classification\n",
    "# from keras.utils import np_utils\n",
    "# y_train = np_utils.to_categorical(y_train, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savez('mfcc_testval_clean', mfcc_df_testval)\n",
    "# savez('mfcc_train_clean', X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Check Types to ensure both sparse/dense matrices\n",
    "print(type(X_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - GMM-MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Due to very large dimensionality of the matrix and problems with local system memory handling the array, we apply PCA and attempt to fit to a reduced matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(0.85, whiten=True)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.fit_transform(X_test)\n",
    "X_val = pca.fit_transform(X_val)\n",
    "\n",
    "n_components = np.arange(750, 2250, 750)\n",
    "models = [GMM(n, covariance_type='spherical', random_state=0).fit(X_train)\n",
    "          for n in n_components]\n",
    "\n",
    "fig, gmm = plt.subplots(figsize=(10, 6))\n",
    "bics = [ model.fit(X_train).bic(X_train) for model in models ]\n",
    "aics = [ model.fit(X_train).aic(X_train) for model in models ]\n",
    "plt.plot(n_components, bics, label='AIC')\n",
    "gmm.legend(loc='best')\n",
    "gmm.set_xlabel('n_components')\n",
    "gmm.set_xticks(np.arange(0, 120, 4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GMM Bayes\n",
    "---------\n",
    "This implements generative classification based on mixtures of gaussians\n",
    "to model the probability density of each class.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import BaseNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "class GMMBayes(BaseNB):\n",
    "    \"\"\"GaussianMixture Bayes Classifier\n",
    "\n",
    "    This is a generalization to the Naive Bayes classifier: rather than\n",
    "    modeling the distribution of each class with axis-aligned gaussians,\n",
    "    GMMBayes models the distribution of each class with mixtures of\n",
    "    gaussians.  This can lead to better classification in some cases.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_components : int or list\n",
    "        number of components to use in the GaussianMixture. If specified as\n",
    "        a list, it must match the number of class labels. Default is 1.\n",
    "    **kwargs : dict, optional\n",
    "        other keywords are passed directly to GaussianMixture\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components=1, **kwargs):\n",
    "        self.n_components = np.atleast_1d(n_components)\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if n_samples != y.shape[0]:\n",
    "            raise ValueError(\"X and y have incompatible shapes\")\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.classes_.sort()\n",
    "        unique_y = self.classes_\n",
    "\n",
    "        n_classes = unique_y.shape[0]\n",
    "\n",
    "        if self.n_components.size not in (1, len(unique_y)):\n",
    "            raise ValueError(\"n_components must be compatible with \"\n",
    "                             \"the number of classes\")\n",
    "\n",
    "        self.gmms_ = [None for i in range(n_classes)]\n",
    "        self.class_prior_ = np.zeros(n_classes)\n",
    "\n",
    "        n_comp = np.zeros(len(self.classes_), dtype=int) + self.n_components\n",
    "        gc.collect()\n",
    "        for i, y_i in enumerate(unique_y):\n",
    "            if n_comp[i] > X[y == y_i].shape[0]:\n",
    "                warnstr = (\"Expected n_samples >= n_components but got \"\n",
    "                           \"n_samples={0}, n_components={1}, \"\n",
    "                           \"n_components set to {0}.\")\n",
    "                warnings.warn(warnstr.format(X[y == y_i].shape[0], n_comp[i]))\n",
    "                n_comp[i] = y_i\n",
    "            self.gmms_[i] = GaussianMixture(n_comp[i], **self.kwargs).fit(X[y == y_i])\n",
    "            self.class_prior_[i] = np.float(np.sum(y == y_i)) / n_samples\n",
    "            gc.collect()\n",
    "        return self\n",
    "\n",
    "    def _joint_log_likelihood(self, X):\n",
    "        \n",
    "        X = np.asarray(np.atleast_2d(X))\n",
    "        logprobs = np.array([g.score_samples(X) for g in self.gmms_]).T\n",
    "        return logprobs + np.log(self.class_prior_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Fit the GMMNaive Bayes classifier to the reduced dimensions\n",
    "gmm_nb = GMMBayes(250) # 250 components per class\n",
    "gmm_nb.fit(X_train, y_train)\n",
    "gc.collect()\n",
    "# now predict\n",
    "y_pred = gmm_nb.predict(X_train)\n",
    "\n",
    "#get completeness score (equivalent to recall)\n",
    "completeness_score = recall_score(y_train,y_pred, average='weighted')\n",
    "#get contamination score (equivalent to 1-precision)\n",
    "contamination_score = (1-precision_score(y_train,y_pred, average='weighted'))\n",
    "\n",
    "print('Completeness: %f'%completeness_score)\n",
    "print('Contamination: %f'%contamination_score)\n",
    "filename = 'gmm_model_09_06.sav'\n",
    "pickle.dump(gmm_nb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GMMNaive Bayes classifier to the reduced dimensions\n",
    "gmm_nb = GMMBayes(500) # 500 components per class\n",
    "gmm_nb.fit(X_train, y_train)\n",
    "gc.collect()\n",
    "# now predict\n",
    "y_pred = gmm_nb.predict(X_train)\n",
    "\n",
    "#get completeness score (equivalent to recall)\n",
    "completeness_score = recall_score(y_train,y_pred, average='weighted')\n",
    "#get contamination score (equivalent to 1-precision)\n",
    "contamination_score = (1-precision_score(y_train,y_pred, average='weighted'))\n",
    "\n",
    "print('Completeness: %f'%completeness_score)\n",
    "print('Contamination: %f'%contamination_score)\n",
    "filename = 'gmm_model_10_06.sav'\n",
    "pickle.dump(gmm_nb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GMMNaive Bayes classifier to the reduced dimensions\n",
    "gmm_nb = GMMBayes(750) # 750 components per class\n",
    "gmm_nb.fit(X_train, y_train)\n",
    "gc.collect()\n",
    "# now predict\n",
    "y_pred = gmm_nb.predict(X_train)\n",
    "\n",
    "#get completeness score (equivalent to recall)\n",
    "completeness_score = recall_score(y_train,y_pred, average='weighted')\n",
    "#get contamination score (equivalent to 1-precision)\n",
    "contamination_score = (1-precision_score(y_train,y_pred, average='weighted'))\n",
    "\n",
    "print('Completeness: %f'%completeness_score)\n",
    "print('Contamination: %f'%contamination_score)\n",
    "filename = 'gmm_model_10_06_750.sav'\n",
    "pickle.dump(gmm_nb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GMMNaive Bayes classifier to the reduced dimensions\n",
    "gmm_nb = GMMBayes(1000) # 1000 components per class\n",
    "gmm_nb.fit(X_train, y_train)\n",
    "gc.collect()\n",
    "# now predict\n",
    "y_pred = gmm_nb.predict(X_train)\n",
    "\n",
    "#get completeness score (equivalent to recall)\n",
    "completeness_score = recall_score(y_train,y_pred, average='weighted')\n",
    "#get contamination score (equivalent to 1-precision)\n",
    "contamination_score = (1-precision_score(y_train,y_pred, average='weighted'))\n",
    "\n",
    "print('Completeness: %f'%completeness_score)\n",
    "print('Contamination: %f'%contamination_score)\n",
    "filename = 'gmm_model_13_06_1000.sav'\n",
    "pickle.dump(gmm_nb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GMMNaive Bayes classifier to the reduced dimensions\n",
    "gmm_nb = GMMBayes(1500) # 2000 components per class\n",
    "gmm_nb.fit(X_train, y_train)\n",
    "gc.collect()\n",
    "# now predict\n",
    "y_pred = gmm_nb.predict(X_train)\n",
    "\n",
    "#get completeness score (equivalent to recall)\n",
    "completeness_score = recall_score(y_train,y_pred, average='weighted')\n",
    "#get contamination score (equivalent to 1-precision)\n",
    "contamination_score = (1-precision_score(y_train,y_pred, average='weighted'))\n",
    "\n",
    "print('Completeness: %f'%completeness_score)\n",
    "print('Contamination: %f'%contamination_score)\n",
    "filename = 'gmm_model_13_06_1500.sav'\n",
    "pickle.dump(gmm_nb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "def model_load_test(filename, X_train, y_train, X_test, y_test):\n",
    "    gmm_nb = pickle.load(open(filename, 'rb'))\n",
    "    y_pred = gmm_nb.predict(X_train)\n",
    "\n",
    "    #get completeness score (equivalent to recall)\n",
    "    completeness_score = recall_score(y_train,y_pred, average='weighted')\n",
    "    #get contamination score (equivalent to 1-precision)\n",
    "    contamination_score = (1-precision_score(y_train,y_pred, average='weighted'))\n",
    "    print('Completeness: %f'%completeness_score)\n",
    "    print('Contamination: %f'%contamination_score)\n",
    "    \n",
    "    result = loaded_model.score(X_test, Y_test)\n",
    "    print(result)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_test('gmm_model_13_06_1500.sav', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-149598a570b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# np.column_stack((y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-268-2de8a5bba4f4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-268-2de8a5bba4f4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    NEED TO TEST HERE\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "NEED TO TEST HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating spectrogram files for every training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_spectrogram(raw_train_data, label):\n",
    "    dirname = os.getcwd()\n",
    "    pathlib.Path(dirname + \"/\" + label + '/images').mkdir(parents=True, exist_ok=True)\n",
    "    fig,ax = plt.subplots(1)\n",
    "    for index, row in raw_train_data.iterrows():\n",
    "        samplingFrequency, signalData = wavfile.read(dirname + \"/\" + row['Label'] + \"/\" + row['FileName'])\n",
    "        fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "        ax.axis('off')\n",
    "        pxx, freqs, bins, im = ax.specgram(x=signalData, Fs=samplingFrequency, noverlap=240, NFFT=512, cmap='viridis')\n",
    "        ax.axis('off')\n",
    "        fig.savefig(dirname + \"/\" + label + '/images/' + row[\"FileName\"] +'.png', dpi=300, frameon='false', transparent=True)\n",
    "        plt.cla()\n",
    "    plt.close(fig)\n",
    "        \n",
    "for df, label in zip(df_train_sublist, labels):\n",
    "    graph_spectrogram(eval(df), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the same to test array\n",
    "dirname = os.getcwd()\n",
    "for label in labels:\n",
    "    pathlib.Path(dirname + \"/\" + 'test/' + label).mkdir(parents=True, exist_ok=True)\n",
    "fig,ax = plt.subplots(1)\n",
    "for row in test_set:\n",
    "    samplingFrequency, signalData = wavfile.read(dirname + \"/\" + row[1] + \"/\" + row[0])\n",
    "    fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "    ax.axis('off')\n",
    "    pxx, freqs, bins, im = ax.specgram(x=signalData, Fs=samplingFrequency, noverlap=240, NFFT=512, cmap='viridis')\n",
    "    ax.axis('off')\n",
    "    fig.savefig(dirname + \"/\" + 'test/' + row[1] + '/'+ row[0] +'.png', dpi=300, frameon='false', transparent=True)\n",
    "    plt.cla()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the same to val array\n",
    "dirname = os.getcwd()\n",
    "for label in labels:\n",
    "    pathlib.Path(dirname + \"/\" + 'val/' + label).mkdir(parents=True, exist_ok=True)\n",
    "fig,ax = plt.subplots(1)\n",
    "for row in val_set:\n",
    "    samplingFrequency, signalData = wavfile.read(dirname + \"/\" + row[1] + \"/\" + row[0])\n",
    "    fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "    ax.axis('off')\n",
    "    pxx, freqs, bins, im = ax.specgram(x=signalData, Fs=samplingFrequency, noverlap=240, NFFT=512, cmap='viridis')\n",
    "    ax.axis('off')\n",
    "    fig.savefig(dirname + \"/\" + 'val/' + row[1] + '/'+ row[0] +'.png', dpi=300, frameon='false', transparent=True)\n",
    "    plt.cla()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the first instance, the data was passed to the CNN by means of the ImageDataGenerator function. In order to make use of better processing power through Google Colab and hence perform more experiments, this was then replaced by the Colab variant explained further on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15461 images belonging to 10 classes.\n",
      "Found 2286 images belonging to 10 classes.\n",
      "Found 4649 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, # rescale all pixel values from 0-255, so aftre this step all our pixel values are in range (0,1)\n",
    "        shear_range=0.2, #to apply some random tranfromations\n",
    "        zoom_range=0.2,#to apply zoom\n",
    "        horizontal_flip=True) # image will be flipper horiz\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "dirname = os.getcwd()\n",
    "\n",
    "img_height, img_width = (64,64)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        dirname,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        color_mode = 'grayscale',\n",
    "        class_mode='categorical',\n",
    "        classes = list(labels),\n",
    "        shuffle = True)\n",
    "\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "        dirname+'/val/',\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        color_mode = 'grayscale',\n",
    "        class_mode='categorical',\n",
    "        classes = list(labels))\n",
    "\n",
    "testing_set = test_datagen.flow_from_directory(\n",
    "        dirname+'/test/',\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        color_mode = 'grayscale',\n",
    "        class_mode='categorical',\n",
    "        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 508,042\n",
      "Trainable params: 508,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/64\n",
      "483/483 [==============================] - 1353s 3s/step - loss: 2.1546 - acc: 0.1834 - val_loss: 2.6570 - val_acc: 0.0892\n",
      "Epoch 2/64\n",
      "483/483 [==============================] - 1191s 2s/step - loss: 1.9010 - acc: 0.3061 - val_loss: 2.2154 - val_acc: 0.2515\n",
      "Epoch 3/64\n",
      "483/483 [==============================] - 1237s 3s/step - loss: 1.4496 - acc: 0.4889 - val_loss: 1.9662 - val_acc: 0.3211\n",
      "Epoch 4/64\n",
      "483/483 [==============================] - 1225s 3s/step - loss: 1.1511 - acc: 0.5945 - val_loss: 2.0470 - val_acc: 0.3705\n",
      "Epoch 5/64\n",
      "483/483 [==============================] - 1231s 3s/step - loss: 0.9504 - acc: 0.6738 - val_loss: 1.8000 - val_acc: 0.4479\n",
      "Epoch 6/64\n",
      "483/483 [==============================] - 1196s 2s/step - loss: 0.8322 - acc: 0.7200 - val_loss: 1.6737 - val_acc: 0.4882\n",
      "Epoch 7/64\n",
      "483/483 [==============================] - 1082s 2s/step - loss: 0.7405 - acc: 0.7539 - val_loss: 1.5816 - val_acc: 0.5407\n",
      "Epoch 8/64\n",
      "483/483 [==============================] - 1046s 2s/step - loss: 0.6602 - acc: 0.7797 - val_loss: 1.4205 - val_acc: 0.6045\n",
      "Epoch 9/64\n",
      "483/483 [==============================] - 1088s 2s/step - loss: 0.6072 - acc: 0.8036 - val_loss: 1.1599 - val_acc: 0.6754\n",
      "Epoch 10/64\n",
      "483/483 [==============================] - 1084s 2s/step - loss: 0.5599 - acc: 0.8161 - val_loss: 1.4234 - val_acc: 0.6304\n",
      "Epoch 11/64\n",
      "483/483 [==============================] - 1075s 2s/step - loss: 0.5140 - acc: 0.8335 - val_loss: 1.4296 - val_acc: 0.5669\n",
      "Epoch 12/64\n",
      "483/483 [==============================] - 1092s 2s/step - loss: 0.4857 - acc: 0.8399 - val_loss: 1.0673 - val_acc: 0.6982\n",
      "Epoch 13/64\n",
      "483/483 [==============================] - 1070s 2s/step - loss: 0.4626 - acc: 0.8492 - val_loss: 1.1357 - val_acc: 0.6969\n",
      "Epoch 14/64\n",
      "483/483 [==============================] - 1076s 2s/step - loss: 0.4347 - acc: 0.8604 - val_loss: 1.0472 - val_acc: 0.7100\n",
      "Epoch 15/64\n",
      "483/483 [==============================] - 1039s 2s/step - loss: 0.4166 - acc: 0.8668 - val_loss: 0.9832 - val_acc: 0.7170\n",
      "Epoch 16/64\n",
      "483/483 [==============================] - 1086s 2s/step - loss: 0.4015 - acc: 0.8713 - val_loss: 1.2278 - val_acc: 0.6859\n",
      "Epoch 17/64\n",
      "483/483 [==============================] - 1082s 2s/step - loss: 0.3864 - acc: 0.8765 - val_loss: 0.9501 - val_acc: 0.7323\n",
      "Epoch 18/64\n",
      "483/483 [==============================] - 1083s 2s/step - loss: 0.3710 - acc: 0.8800 - val_loss: 0.9701 - val_acc: 0.7340\n",
      "Epoch 19/64\n",
      "483/483 [==============================] - 1083s 2s/step - loss: 0.3660 - acc: 0.8845 - val_loss: 0.9085 - val_acc: 0.7450\n",
      "Epoch 20/64\n",
      "483/483 [==============================] - 1082s 2s/step - loss: 0.3597 - acc: 0.8853 - val_loss: 0.9579 - val_acc: 0.7577\n",
      "Epoch 21/64\n",
      "483/483 [==============================] - 1055s 2s/step - loss: 0.3511 - acc: 0.8904 - val_loss: 1.2143 - val_acc: 0.7248\n",
      "Epoch 22/64\n",
      "483/483 [==============================] - 1063s 2s/step - loss: 0.3413 - acc: 0.8904 - val_loss: 0.8655 - val_acc: 0.7524\n",
      "Epoch 23/64\n",
      "483/483 [==============================] - 1077s 2s/step - loss: 0.3354 - acc: 0.8941 - val_loss: 0.9643 - val_acc: 0.7533\n",
      "Epoch 24/64\n",
      "483/483 [==============================] - 1080s 2s/step - loss: 0.3210 - acc: 0.8997 - val_loss: 1.0414 - val_acc: 0.7437\n",
      "Epoch 25/64\n",
      "483/483 [==============================] - 1079s 2s/step - loss: 0.3098 - acc: 0.9012 - val_loss: 1.0610 - val_acc: 0.7428\n",
      "Epoch 26/64\n",
      "483/483 [==============================] - 1139s 2s/step - loss: 0.3110 - acc: 0.9008 - val_loss: 0.9849 - val_acc: 0.7397\n",
      "Epoch 27/64\n",
      "102/483 [=====>........................] - ETA: 14:16 - loss: 0.3083 - acc: 0.9066"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-380081f35167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     epochs = nb_epochs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/speech/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "#Define CNN Model\n",
    "model = Sequential()\n",
    "input_shape = (img_height, img_width, 1)\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "nb_epochs = 20\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#Compile Model\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch = training_set.samples // batch_size,\n",
    "    validation_data = validation_set, \n",
    "    validation_steps = validation_set.samples // batch_size,\n",
    "    epochs = nb_epochs)\n",
    "\n",
    "our_model = model\n",
    "our_model.save('dirname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to attempt more experiments using Google Colab, mounting the spectrogram image files and passing them through the imagedatagenerator was proving to be too slow, so we opted to transform dataset into h5 files, reading the images as numpy arrays, and passing these to the notebook on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_write_data_into_h5_file(dest_filepath, filepaths_list, n_px, n_channels):\n",
    "  \n",
    "    data_shape = (len(filepaths_list), n_px * n_px * n_channels)\n",
    "    dataset_name = \"input_data\"\n",
    "    \n",
    "    with h5py.File(dest_filepath, 'a') as f:\n",
    "        \n",
    "        f.create_dataset(dataset_name, data_shape, np.float32)\n",
    "        \n",
    "        for i in range(len(filepaths_list)):\n",
    "            #if (i+1) % 512 == 0:\n",
    "            #    print('{}/{} files converted'.format((i+1), len(filepaths_list)))\n",
    "\n",
    "            filepath = filepaths_list[i]\n",
    "            img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (n_px, n_px), interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            #Normalize the image - convert the each pixel value between 0 and 1\n",
    "            img = img / 255\n",
    "            #Reshape the image - roll it up into a column vector\n",
    "            img = img.ravel()\n",
    "            \n",
    "            #img[None] makes it a proper array instead of rank 1 array\n",
    "            f[dataset_name][i, ...] = img[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_labels_into_h5_file(dest_filepath, new_labels):\n",
    "    \n",
    "    dataset_name = \"input_labels\"\n",
    "    \n",
    "    with h5py.File(dest_filepath, 'a') as f:\n",
    "        f.create_dataset(dataset_name, (len(new_labels),), np.int8)\n",
    "        f[dataset_name][...] = new_labels\n",
    "        \n",
    "def convert_images_to_data_in_h5_file(src_img_filepath_pattern, dest_h5_file_path, n_px, \n",
    "                                      n_channels = 3, batch_size = 1024):\n",
    "    full_filep = np.empty((0,2))\n",
    "    for label in labels:\n",
    "        temp_filepaths = glob.glob(dirname+'/test/'+label+'/*.png') #Use this for test set\n",
    "#         temp_filepaths = glob.glob(dirname+'/val/'+label+'/*.png') #Use this for validation set\n",
    "#         temp_filepaths = glob.glob(dirname+ '/' + label+'/images/*.png') #Use this for training set\n",
    "        label_list= [label] * len(temp_filepaths)\n",
    "        temp_array = np.column_stack((temp_filepaths, label_list))\n",
    "        full_filep = np.append(full_filep, temp_array, axis=0)\n",
    "\n",
    "    np.random.shuffle(full_filep)\n",
    "#     print(full_filep)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    full_filep[:,1] = le.fit_transform(full_filep[:,1])\n",
    "    full_filepaths = list(full_filep[:,0])\n",
    "    new_labels = list(full_filep[:,1].astype(int))\n",
    "    t = list(zip(full_filepaths, new_labels))\n",
    "    shuffle(t)\n",
    "    #Get the shuffled filepaths & labels\n",
    "    src_filepaths, new_labels = zip(*t)\n",
    "\n",
    "#     print(full_filepaths)\n",
    "    \n",
    "    #Number of images\n",
    "    m = len(src_filepaths)\n",
    "#     print(m)\n",
    "    n_complete_batches = math.ceil(m / batch_size)\n",
    "#     print(n_complete_batches)\n",
    "    \n",
    "    for i in range(n_complete_batches):\n",
    "        print('Creating file', (i+1))\n",
    "        \n",
    "        dest_file_path = dest_h5_file_path + str(i + 1) + \".h5\"   \n",
    "        \n",
    "        start_pos = i * batch_size\n",
    "        end_pos = min(start_pos + batch_size, m)\n",
    "        src_filepaths_batch = src_filepaths[start_pos: end_pos]\n",
    "        labels_batch = new_labels[start_pos: end_pos]\n",
    "#         print(labels_batch)\n",
    "        normalize_and_write_data_into_h5_file(dest_file_path, src_filepaths_batch, n_px, n_channels)\n",
    "        write_labels_into_h5_file(dest_file_path, labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file 1\n",
      "(8, 4, 1, 7, 6, 1, 9, 8, 6, 5, 3, 7, 6, 2, 1, 4, 5, 6, 3, 2, 5, 3, 1, 3, 3, 3, 9, 7, 2, 7, 7, 6, 4, 3, 2, 2, 2, 1, 8, 7, 8, 6, 5, 7, 2, 5, 3, 3, 3, 5, 6, 1, 4, 7, 6, 5, 7, 5, 8, 1, 6, 3, 3, 2, 7, 3, 4, 4, 3, 5, 7, 4, 2, 5, 2, 1, 8, 5, 8, 5, 5, 3, 3, 3, 5, 5, 6, 3, 8, 7, 2, 7, 6, 3, 4, 8, 2, 5, 4, 5, 7, 7, 4, 9, 3, 8, 5, 1, 8, 4, 5, 3, 1, 2, 7, 7, 3, 4, 2, 7, 3, 9, 4, 3, 7, 7, 7, 5, 2, 5, 2, 3, 3, 5, 5, 6, 1, 1, 6, 3, 3, 3, 4, 7, 1, 5, 2, 5, 3, 1, 1, 3, 2, 7, 1, 1, 4, 6, 5, 3, 6, 7, 2, 2, 2, 4, 2, 3, 3, 5, 8, 3, 5, 6, 6, 1, 1, 9, 7, 1, 4, 7, 2, 3, 8, 3, 8, 1, 5, 6, 3, 4, 3, 2, 2, 7, 3, 7, 6, 1, 3, 4, 4, 5, 4, 5, 5, 1, 2, 3, 7, 8, 6, 5, 1, 8, 7, 6, 7, 1, 2, 2, 6, 8, 7, 5, 5, 1, 8, 2, 7, 9, 8, 2, 3, 1, 8, 5, 2, 5, 1, 6, 5, 3, 3, 1, 5, 3, 5, 6, 2, 8, 6, 4, 5, 6, 3, 1, 4, 1, 2, 4, 7, 2, 4, 3, 2, 2, 2, 2, 3, 3, 5, 8, 8, 6, 7, 3, 1, 7, 6, 5, 2, 5, 5, 4, 1, 7, 4, 0, 2, 2, 4, 3, 7, 8, 6, 5, 3, 3, 8, 7, 2, 2, 3, 3, 5, 5, 8, 4, 1, 2, 1, 2, 5, 5, 4, 8, 5, 5, 7, 7, 8, 5, 7, 6, 2, 7, 1, 7, 3, 3, 7, 7, 6, 7, 7, 3, 4, 5, 6, 6, 4, 3, 5, 5, 2, 2, 2, 1, 3, 7, 8, 2, 6, 3, 2, 5, 2, 5, 5, 3, 6, 1, 6, 3, 6, 3, 2, 2, 4, 6, 2, 5, 3, 7, 4, 2, 1, 7, 8, 3, 7, 1, 4, 8, 3, 4, 2, 3, 4, 6, 7, 1, 5, 8, 8, 1, 8, 1, 5, 7, 2, 6, 1, 7, 7, 5, 2, 5, 6, 6, 6, 8, 6, 8, 1, 2, 7, 7, 2, 6, 5, 1, 6, 3, 8, 7, 6, 3, 9, 5, 6, 3, 5, 7, 2, 4, 2, 4, 5, 1, 3, 6, 2, 3, 5, 7, 8, 5, 2, 1, 3, 3, 7, 2, 1, 4, 5, 7, 4, 7, 5, 8, 5, 1, 7, 8, 2, 4, 2, 3, 4, 2, 4, 3, 2, 3, 3, 3, 3, 2, 1, 7, 5, 8, 8, 3, 5, 1, 6, 7, 1, 2, 6, 4, 6, 5, 5, 2, 9, 8, 1, 3, 2, 2, 2, 2, 2, 1, 2, 3, 8, 5, 5, 7, 7, 3, 1, 1, 3, 4, 6, 5, 5, 4, 3, 2, 5, 2, 3, 2, 8, 4, 6, 7, 3, 4, 1, 5, 1, 6, 2, 7, 3, 5, 7, 3, 1, 7, 6, 3, 5, 2, 2, 5, 2, 2, 5, 7, 3, 4, 9, 6, 1, 8, 2, 3, 3, 7, 8, 2, 1, 2, 5, 8, 7, 5, 1, 4, 1, 3, 2, 7, 5, 4, 1, 3, 4, 6, 6, 5, 5, 3, 7, 3, 8, 8, 3, 7, 7, 6, 2, 1, 7, 8, 5, 3, 6, 1, 5, 5, 5, 3, 7, 5, 1, 5, 3, 3, 5, 6, 1, 7, 1, 7, 8, 6, 5, 3, 1, 6, 3, 3, 4, 3, 6, 2, 4, 5, 4, 3, 6, 4, 7, 1, 5, 3, 2, 1, 3, 1, 2, 1, 4, 7, 8, 5, 2, 2, 1, 2, 2, 4, 3, 2, 1, 1, 4, 6, 7, 5, 3, 5, 5, 7, 4, 8, 3, 4, 7, 4, 5, 3, 8, 9, 5, 1, 4, 3, 4, 6, 5, 2, 2, 5, 5, 5, 4, 1, 5, 2, 7, 7, 1, 2, 2, 5, 1, 8, 3, 1, 1, 2, 5, 8, 1, 7, 2, 7, 1, 3, 6, 3, 5, 5, 7, 3, 1, 3, 7, 7, 6, 5, 8, 3, 1, 1, 1, 1, 3, 2, 1, 4, 7, 5, 5, 5, 1, 3, 4, 1, 3, 2, 3, 3, 1, 7, 4, 2, 6, 4, 3, 2, 3, 8, 3, 3, 6, 4, 7, 3, 7, 4, 2, 3, 7, 6, 3, 6, 6, 5, 1, 2, 2, 7, 5, 5, 5, 5, 6, 2, 1, 7, 4, 3, 5, 7, 2, 3, 4, 6, 6, 5, 4, 1, 6, 5, 1, 1, 5, 5, 3, 7, 0, 1, 1, 2, 6, 3, 1, 7, 7, 1, 7, 7, 6, 1, 1, 2, 8, 3, 4, 7, 9, 2, 3, 3, 8, 3, 5, 7, 4, 1, 6, 1, 5, 5, 3, 8, 7, 1, 2, 3, 1, 1, 5, 1, 7, 6, 4, 4, 3, 2, 9, 7, 7, 3, 4, 4, 6, 3, 4, 8, 8, 4, 3, 5, 1, 8, 7, 5, 3, 2, 7, 6, 3, 2, 7, 2, 8, 3, 7, 3, 2, 8, 5, 2, 5, 3, 5, 5, 2, 8, 4, 5, 1, 1, 5, 2, 5, 2, 3, 3, 3, 4, 1, 3, 5, 7, 2, 8, 5, 5, 6, 3, 5, 2, 0, 3, 2, 3, 3, 1, 7, 2, 3, 5, 7, 1, 3, 7, 3, 1, 5, 8, 3, 3, 5, 2, 6, 7, 4, 2, 3, 8, 3, 9, 2, 2, 8, 2, 4, 3, 8, 3, 7, 1, 2, 8, 5, 6, 2, 1, 7, 4, 2, 1, 3, 1, 7, 7, 3, 5, 2, 6, 2, 5, 7, 5, 3, 1, 6, 2, 1, 3, 3, 3, 4, 5, 2, 7, 5, 9, 6, 3, 3, 2, 1, 2, 3, 3, 1, 7, 5, 1, 4, 6, 7, 1, 7, 1, 8, 6)\n",
      "Creating file 2\n",
      "(5, 2, 5, 7, 6, 4, 3, 6, 1, 3, 7, 3, 6, 1, 9, 2, 6, 4, 1, 6, 1, 2, 6, 7, 3, 2, 1, 1, 1, 0, 2, 7, 3, 7, 6, 6, 1, 6, 4, 1, 2, 1, 5, 1, 3, 7, 5, 8, 1, 8, 2, 5, 5, 3, 5, 7, 0, 8, 6, 6, 4, 7, 1, 2, 8, 2, 4, 6, 2, 1, 7, 4, 2, 8, 2, 7, 3, 2, 7, 7, 4, 1, 3, 7, 6, 8, 2, 2, 2, 8, 1, 1, 4, 3, 5, 4, 8, 3, 3, 6, 7, 2, 5, 5, 2, 1, 1, 7, 1, 1, 3, 1, 3, 1, 4, 2, 2, 7, 2, 8, 8, 7, 5, 3, 1, 1, 6, 1, 1, 5, 6, 5, 6, 3, 7, 2, 5, 2, 5, 4, 8, 4, 3, 3, 6, 5, 5, 5, 5, 3, 6, 5, 4, 2, 4, 4, 8, 1, 7, 5, 2, 1, 7, 1, 5, 3, 2, 5, 3, 5, 1, 5, 4, 7, 1, 4, 3, 7, 7, 8, 0, 5, 6, 6, 3, 3, 2, 6, 7, 3, 2, 2, 2, 5, 1, 2, 1, 3, 6, 2, 8, 2, 3, 2, 8, 8, 2, 1, 1, 7, 8, 1, 4, 6, 2, 7, 5, 7, 3, 5, 8, 8, 6, 3, 1, 7, 2, 6, 9, 1, 2, 5, 7, 3, 4, 7, 7, 5, 8, 7, 7, 7, 3, 6, 5, 5, 8, 1, 1, 7, 6, 2, 7, 1, 8, 1, 4, 2, 2, 3, 3, 7, 2, 3, 4, 1, 4, 6, 3, 3, 3, 2, 5, 1, 7, 2, 5, 7, 7, 4, 6, 2, 7, 7, 1, 3, 8, 1, 1, 2, 5, 0, 8, 5, 5, 5, 2, 5, 3, 3, 4, 1, 4, 5, 8, 5, 5, 3, 7, 7, 3, 6, 5, 7, 4, 7, 5, 1, 5, 1, 7, 8, 5, 7, 7, 6, 1, 4, 1, 8, 2, 4, 9, 7, 3, 0, 7, 2, 5, 6, 9, 3, 5, 2, 1, 4, 9, 4, 3, 1, 6, 8, 3, 8, 5, 2, 3, 7, 6, 2, 8, 3, 2, 7, 3, 4, 3, 6, 4, 1, 8, 8, 4, 6, 5, 3, 6, 2, 8, 3, 5, 2, 5, 8, 5, 5, 3, 3, 5, 4, 2, 2, 2, 2, 1, 1, 7, 8, 8, 8, 2, 8, 2, 9, 3, 8, 5, 7, 4, 9, 5, 7, 6, 1, 3, 5, 1, 6, 7, 7, 3, 7, 8, 4, 2, 1, 7, 4, 1, 7, 3, 6, 4, 7, 2, 1, 7, 7, 5, 6, 6, 3, 3, 7, 4, 4, 7, 7, 9, 3, 1, 4, 8, 8, 5, 8, 3, 5, 2, 4, 3, 4, 7, 6, 5, 8, 8, 1, 3, 1, 2, 5, 2, 6, 4, 3, 3, 2, 3, 4, 1, 4, 6, 4, 7, 2, 8, 2, 5, 1, 1, 2, 7, 8, 1, 7, 8, 7, 3, 5, 5, 5, 8, 7, 8, 6, 4, 7, 4, 2, 2, 5, 2, 7, 8, 8, 3, 4, 6, 8, 5, 2, 4, 5, 1, 1, 8, 3, 4, 8, 5, 7, 8, 3, 5, 7, 8, 5, 7, 4, 9, 7, 3, 1, 3, 2, 8, 1, 7, 3, 1, 7, 8, 6, 7, 2, 7, 0, 1, 3, 1, 2, 7, 1, 4, 3, 8, 6, 7, 3, 5, 5, 7, 6, 5, 3, 4, 6, 7, 8, 4, 4, 3, 1, 5, 5, 2, 7, 8, 2, 1, 1, 3, 3, 7, 1, 8, 7, 2, 7, 2, 6, 8, 4, 3, 1, 4, 7, 7, 3, 1, 3, 5, 3, 3, 1, 1, 6, 3, 6, 3, 1, 6, 3, 7, 8, 9, 7, 8, 4, 1, 2, 1, 6, 4, 4, 6, 1, 8, 9, 6, 1, 9, 5, 7, 2, 7, 2, 4, 8, 9, 2, 8, 5, 4, 2, 1, 8, 6, 7, 8, 4, 3, 5, 5, 3, 3, 6, 4, 2, 3, 4, 3, 1, 4, 2, 7, 6, 3, 9, 5, 7, 6, 8, 3, 1, 2, 7, 7, 7, 3, 9, 7, 7, 5, 4, 5, 1, 4, 2, 2, 5, 4, 1, 5, 1, 2, 8, 2, 2, 5, 3, 4, 2, 2, 3, 7, 3, 8, 2, 8, 4, 5, 2, 3, 8, 1, 7, 4, 8, 1, 5, 7, 0, 3, 1, 2, 4, 7, 1, 2, 6, 5, 4, 4, 3, 7, 3, 7, 5, 5, 5, 6, 4, 2, 3, 8, 3, 6, 6, 3, 6, 3, 7, 5, 3, 3, 2, 2, 2, 7, 3, 1, 7, 5, 3, 8, 5, 3, 7, 5, 4, 7, 7, 1, 8, 3, 2, 8, 5, 1, 2, 5, 5, 3, 3, 7, 4, 6, 2, 7, 8, 8, 5, 2, 3, 2, 1, 5, 7, 2, 1, 5, 3, 4, 5, 8, 5, 5, 8, 3, 1, 1, 3, 2, 2, 7, 4, 4, 2, 3, 2, 8, 3, 6, 4, 6, 3, 4, 3, 2, 6, 3, 2, 1, 4, 5, 7, 4, 3, 2, 1, 7, 4, 0, 4, 2, 1, 7, 2, 6, 8, 2, 7, 5, 6, 2, 5, 6, 1, 3, 5, 4, 2, 8, 5, 5, 8, 7, 2, 2, 1, 1, 1, 3, 7, 7, 7, 4, 6, 5, 3, 5, 1, 5, 1, 4, 3, 8, 5, 4, 3, 8, 0, 4, 5, 7, 7, 1, 6, 3, 7, 1, 7, 1, 7, 1, 3, 6, 7, 4, 7, 2, 8, 2, 3, 1, 7, 4, 1, 5, 3, 1, 1, 6, 4, 5, 7, 2, 1, 1, 7, 2, 6, 5, 5, 7, 1, 2, 5, 1, 1, 3, 3, 2, 7, 1, 6, 3, 3, 2, 6, 5, 2, 1, 8, 2, 3, 1, 5, 2, 1, 5, 3, 5, 8, 6, 3, 5, 5, 1, 2, 7, 2, 8, 3, 5, 7, 3, 2, 3, 4, 2, 5, 2, 1, 6, 0, 5, 3, 7, 2, 4, 4, 5, 4, 8, 6, 2, 5, 3, 3, 3, 2, 2, 1, 6, 4, 8, 4, 7, 8, 7, 1)\n",
      "Creating file 3\n",
      "(1, 6, 2, 4, 2, 7, 1, 2, 2, 3, 2, 6, 5, 7, 7, 6, 4, 7, 6, 2, 3, 2, 3, 5, 5, 5, 1, 6, 5, 7, 5, 2, 6, 3, 1, 7, 5, 7, 3, 7, 2, 7, 7, 2, 7, 3, 7, 7, 1, 7, 7, 7, 3, 1, 3, 2, 4, 4, 5, 3, 2, 2, 8, 4, 5, 8, 5, 8, 2, 3, 4, 3, 4, 7, 4, 1, 1, 5, 5, 5, 7, 3, 2, 7, 1, 8, 8, 1, 5, 2, 2, 6, 2, 7, 2, 1, 7, 6, 8, 7, 1, 6, 5, 3, 6, 5, 6, 1, 6, 8, 7, 4, 1, 1, 2, 7, 4, 8, 7, 1, 1, 8, 2, 2, 5, 8, 7, 4, 3, 7, 5, 5, 4, 6, 2, 1, 7, 7, 4, 2, 7, 5, 5, 5, 7, 3, 4, 5, 3, 3, 5, 4, 7, 6, 2, 5, 5, 8, 7, 5, 8, 5, 6, 3, 8, 4, 1, 8, 1, 6, 1, 3, 8, 5, 7, 1, 5, 4, 3, 5, 8, 3, 8, 2, 7, 3, 1, 2, 3, 2, 1, 3, 3, 3, 1, 8, 5, 3, 5, 3, 2, 5, 5, 6, 3, 7, 5, 4, 6, 2, 2, 2, 5, 3, 4, 7, 2, 5, 3, 3, 1, 7, 2, 1, 1, 5, 1, 5, 1, 1, 8, 6, 7, 5, 1, 1, 2, 1, 7, 7, 2, 2, 5, 1, 2, 4, 1, 4, 3, 6, 5, 1, 5, 7, 5, 3, 4, 8, 4, 4, 6, 7, 2, 5, 4, 1, 2, 3, 1, 5, 7, 3, 1, 2, 8, 2, 4, 8, 4, 2, 9, 3, 7, 7, 6, 8, 8, 4, 2, 1, 5, 6, 8, 3, 1, 8, 7, 7, 6, 5, 2, 5, 8, 1, 1, 2, 1, 7, 2, 1, 3, 6, 4, 6, 7, 2, 3, 6, 1, 2, 1, 5, 1, 7, 2, 7, 2, 2, 8, 5, 3, 7, 6, 3, 5, 6, 9, 8, 6, 7, 1, 5, 3, 5, 8, 1, 3, 7, 5, 2, 3, 2, 2, 5, 3, 8, 5, 3, 7, 8, 6, 2, 7, 3, 6, 5, 1, 1, 8, 7, 7, 6, 7, 8, 8, 8, 6, 2, 4, 6, 3, 4, 3, 7, 1, 2, 6, 3, 8, 1, 6, 5, 1, 4, 8, 7, 4, 6, 7, 8, 3, 5, 7, 1, 2, 8, 2, 2, 7, 8, 8, 5, 8, 1, 4, 7, 1, 2, 1, 7, 8, 5, 7, 8, 8, 2, 3, 4, 8, 1, 7, 6, 2, 2, 1, 2, 3, 1, 6, 7, 2, 7, 3, 6, 7, 7, 5, 3, 2, 5, 5, 1, 6, 6, 1, 6, 3, 8, 8, 5, 8, 4, 3, 1, 1, 3, 8, 1, 7, 1, 3, 9, 2, 8, 8, 6, 2, 3, 4, 4, 6, 2, 7, 5, 2, 1, 3, 3, 2, 5, 7, 7, 1, 7, 5, 5, 4, 7, 1, 1, 5, 9, 7, 5, 5, 3, 7, 7, 3, 5, 3, 6, 7, 1, 2, 5, 8, 4, 2, 8, 3, 2, 4, 7, 1, 5, 4, 2, 7, 3, 1, 7, 2, 1, 2, 7, 7, 1, 3, 3, 1, 3, 2, 2, 4, 2, 8, 5, 3, 3, 2, 3, 1, 3, 2, 5, 2, 1, 7, 0, 5, 4, 8, 7, 8, 3, 8, 2, 3, 3, 1, 7, 8, 5, 6, 3, 2, 1, 3, 8, 3, 3, 7, 4, 8, 5, 5, 5, 2, 3, 6, 5, 2, 2, 0, 7, 3, 5, 6, 5, 5, 5, 7, 5, 5, 6, 6, 7, 5, 3, 2, 1, 2, 4, 2, 1, 2, 5, 7, 5, 6, 7, 7, 6, 7, 6, 7, 8, 7, 7, 3, 6, 6, 4, 3, 7, 1, 1, 1, 7, 7, 7, 1, 4, 3, 7, 7, 4, 8, 7, 7, 1, 5, 5, 6, 6, 1, 5, 8, 3, 1, 9, 8, 3, 5, 6, 6, 1, 8, 2, 1, 7, 0, 5, 3, 9, 1, 2, 3, 3, 1, 5, 7, 1, 2, 5, 2, 0, 5, 7, 7, 5, 7, 5, 3, 8, 3, 1, 5, 3, 6, 2, 8, 5, 3, 3, 6, 7, 4, 2, 5, 7, 5, 1, 8, 3, 1, 3, 3, 5, 8, 2, 5, 7, 8, 1, 2, 7, 2, 6, 2, 0, 2, 4, 6, 5, 6, 1, 5, 2, 7, 4, 4, 2, 3, 8, 3, 8, 3, 5, 3, 3, 6, 5, 1, 8, 8, 5, 3, 1, 5, 8, 7, 2, 2, 7, 3, 7, 5, 8, 2, 3, 3, 3, 8, 2, 3, 6, 4, 4, 2, 4, 5, 6, 1, 8, 8, 4, 5, 5, 1, 3, 3, 6, 5, 3, 7, 7, 1, 8, 4, 3, 2, 1, 2, 1, 8, 2, 8, 3, 1, 3, 3, 3, 5, 5, 2, 2, 1, 1, 5, 7, 3, 2, 8, 1, 6, 2, 4, 2, 4, 1, 7, 2, 5, 8, 2, 2, 6, 3, 7, 5, 2, 8, 3, 3, 5, 8, 1, 5, 3, 6, 3, 7, 1, 7, 5, 7, 5, 1, 7, 1, 5, 3, 1, 1, 1, 5, 2, 1, 6, 7, 1, 5, 5, 1, 3, 1, 5, 8, 8, 7, 3, 6, 7, 1, 5, 1, 7, 1, 4, 3, 7, 4, 5, 3, 2, 8, 5, 1, 3, 5, 7, 2, 8, 1, 1, 2, 8, 8, 4, 1, 4, 6, 6, 3, 5, 6, 3, 3, 3, 8, 2, 5, 3, 6, 4, 1, 3, 5, 5, 5, 4, 7, 5, 6, 1, 1, 8, 6, 6, 3, 6, 5, 3, 8, 2, 1, 7, 7, 4, 2, 5, 8, 2, 3, 3, 5, 8, 5, 3, 3, 2, 6, 5, 5, 7, 3, 5, 1, 5, 3, 4, 3, 5, 2, 7, 6, 8, 1, 7, 4, 7, 6, 1, 3, 7, 5, 8, 1, 2, 5, 6, 2, 7, 1, 8, 8, 5, 8, 1, 5, 6, 1, 4, 5, 7, 2, 0, 3, 3, 7, 6, 3, 3, 5, 2, 7, 7, 1, 3, 3, 6, 8)\n",
      "Creating file 4\n",
      "(1, 5, 1, 7, 2, 1, 3, 1, 7, 3, 7, 5, 1, 8, 2, 6, 5, 2, 7, 4, 5, 2, 4, 7, 3, 1, 4, 2, 8, 4, 3, 7, 7, 7, 6, 2, 7, 2, 7, 3, 8, 2, 1, 6, 6, 3, 6, 7, 5, 2, 6, 4, 6, 3, 7, 3, 5, 4, 3, 1, 8, 8, 6, 5, 2, 3, 1, 7, 5, 5, 3, 5, 2, 2, 3, 8, 5, 1, 8, 2, 7, 2, 2, 7, 2, 1, 5, 1, 1, 1, 3, 6, 6, 7, 8, 2, 8, 7, 2, 6, 1, 4, 7, 3, 2, 5, 4, 5, 4, 7, 5, 3, 3, 2, 5, 2, 6, 7, 7, 6, 5, 8, 3, 5, 7, 1, 3, 1, 2, 1, 2, 1, 5, 3, 3, 6, 7, 4, 5, 3, 2, 8, 2, 5, 6, 7, 3, 1, 2, 2, 1, 1, 7, 1, 6, 4, 2, 7, 1, 7, 5, 6, 2, 2, 1, 3, 5, 7, 1, 8, 3, 4, 2, 5, 1, 2, 7, 6, 2, 5, 5, 5, 3, 8, 2, 6, 2, 7, 0, 1, 1, 7, 7, 2, 7, 6, 7, 3, 3, 8, 5, 3, 7, 4, 1, 6, 6, 5, 2, 3, 8, 3, 1, 4, 3, 8, 2, 1, 7, 4, 2, 4, 2, 2, 7, 4, 7, 6, 1, 6, 3, 7, 7, 2, 5, 6, 5, 1, 5, 3, 5, 3, 3, 8, 3, 5, 5, 1, 5, 9, 2, 4, 8, 2, 2, 5, 2, 1, 3, 1, 7, 0, 5, 1, 2, 3, 7, 6, 5, 2, 1, 6, 1, 5, 3, 2, 7, 6, 3, 7, 1, 2, 2, 7, 6, 8, 3, 1, 1, 1, 7, 3, 4, 1, 5, 2, 8, 8, 2, 3, 4, 4, 3, 9, 7, 3, 1, 1, 1, 3, 6, 3, 3, 3, 5, 7, 1, 3, 4, 5, 1, 1, 3, 5, 1, 2, 8, 7, 3, 3, 5, 5, 1, 5, 2, 3, 1, 8, 6, 8, 3, 7, 7, 8, 2, 7, 9, 1, 5, 3, 5, 1, 4, 2, 2, 3, 2, 7, 7, 9, 1, 6, 5, 2, 2, 5, 8, 9, 1, 4, 4, 2, 8, 2, 8, 8, 7, 2, 6, 4, 6, 8, 1, 2, 3, 6, 7, 8, 5, 1, 1, 3, 4, 8, 1, 1, 8, 2, 3, 2, 3, 7, 2, 3, 5, 8, 3, 2, 5, 2, 6, 2, 2, 3, 8, 9, 7, 7, 1, 7, 5, 5, 8, 6, 6, 2, 1, 1, 1, 4, 6, 7, 2, 1, 2, 1, 8, 8, 1, 3, 3, 2, 2, 8, 8, 1, 3, 7, 5, 6, 2, 4, 1, 7, 1, 1, 2, 3, 2, 4, 5, 1, 1, 6, 2, 2, 7, 7, 2, 5, 0, 6, 5, 4, 1, 1, 3, 2, 6, 9, 3, 3, 5, 7, 4, 2, 6, 1, 7, 5, 5, 3, 6, 3, 4, 7, 7, 3, 1, 7, 1, 2, 5, 7, 5, 1, 3, 1, 1, 7, 7, 5, 4, 3, 0, 5, 5, 1, 3, 6, 3, 7, 7, 2, 3, 5, 3, 3, 2, 6, 7, 5, 5, 7, 1, 8, 5, 6, 5, 6, 2, 1, 2, 8, 2, 1, 6, 7, 2, 6, 3, 3, 3, 8, 2, 5, 1, 5, 7, 0, 1, 1, 7, 7, 2, 3, 7, 1, 5, 8, 4, 3, 6, 2, 6, 4, 5, 7, 4, 8, 7, 7, 2, 3, 1, 3, 4, 3, 1, 5, 1, 1, 3, 5, 7, 7, 7, 6, 5, 2, 3, 4, 5, 2, 3, 1, 1, 4, 8, 1, 2, 3, 3, 0, 5, 1, 2, 8, 0, 7, 1, 2, 7, 4, 4, 3, 4, 7, 6, 3, 1, 2, 1, 5, 6, 7, 1, 8, 1, 5, 3, 5, 1, 5, 5, 2, 6, 5, 6, 5, 6, 5, 8, 1, 4, 2, 5, 4, 7, 6, 5, 7, 5, 1, 7, 8, 6, 1, 1, 7, 6, 6, 2, 3, 8, 6, 2, 8, 5, 5, 1, 9, 6, 6, 3, 5, 8, 5, 1, 4, 8, 2, 3, 1, 2, 1, 5, 6, 7, 3, 2, 1, 4, 7, 3, 7, 4, 3, 6, 2, 3, 8, 2, 3, 6, 2, 4, 2, 5, 7, 4, 4, 4, 1, 7, 2, 5, 7, 2, 3, 6, 4, 3, 5, 8, 5, 7, 7, 7, 4, 5, 9, 1, 7, 6, 6, 2, 2, 1, 6, 2, 7, 5, 3, 1, 2, 1, 4, 6, 5, 6, 5, 7, 2, 2, 5, 6, 6, 2, 3, 1, 7, 7, 3, 1, 7, 2, 4, 1, 5, 8, 7, 2, 6, 4, 3, 1, 4, 2, 6, 1, 2, 4, 4, 6, 3, 4, 1, 7, 5, 3, 0, 8, 7, 7, 5, 1, 1, 4, 2, 6, 7, 7, 2, 4, 2, 5, 7, 2, 1, 6, 3, 8, 6, 3, 3, 7, 3, 1, 7, 7, 9, 6, 5, 5, 7, 2, 1, 8, 3, 5, 5, 2, 3, 2, 1, 4, 1, 7, 3, 5, 5, 7, 2, 1, 3, 8, 2, 3, 2, 1, 3, 3, 1, 4, 3, 8, 7, 6, 1, 8, 2, 2, 6, 6, 6, 5, 4, 5, 2, 7, 8, 2, 2, 7, 8, 5, 7, 3, 1, 5, 7, 3, 7, 7, 3, 7, 7, 9, 8, 5, 8, 8, 7, 1, 6, 3, 2, 7, 5, 3, 2, 3, 6, 8, 3, 4, 0, 2, 2, 7, 5, 2, 3, 1, 1, 9, 4, 7, 7, 5, 1, 7, 1, 3, 3, 8, 6, 6, 6, 5, 3, 8, 8, 1, 7, 4, 6, 3, 3, 1, 3, 5, 5, 8, 6, 8, 2, 3, 3, 6, 4, 2, 1, 7, 1, 4, 4, 1, 7, 1, 3, 1, 2, 7, 6, 5, 3, 1, 2, 5, 5, 7, 2, 2, 3, 5, 5, 0, 3, 4, 5, 5, 5, 7, 8, 8, 4, 8, 5, 8, 8, 4, 1, 1, 3, 8, 6, 5, 2, 4, 8, 2, 5, 3, 5, 1, 7, 5, 4, 1, 5, 7, 8)\n",
      "Creating file 5\n",
      "(7, 7, 1, 4, 5, 3, 5, 1, 1, 1, 6, 6, 1, 5, 5, 7, 3, 6, 1, 7, 1, 6, 8, 7, 1, 8, 1, 2, 6, 1, 2, 4, 3, 1, 1, 3, 1, 7, 6, 1, 4, 3, 1, 3, 5, 5, 4, 6, 5, 2, 5, 7, 3, 7, 3, 3, 7, 1, 8, 1, 8, 3, 1, 3, 9, 2, 2, 5, 6, 5, 3, 5, 8, 4, 6, 6, 1, 8, 1, 1, 8, 7, 2, 8, 5, 5, 5, 2, 3, 4, 2, 7, 1, 5, 1, 5, 1, 4, 4, 2, 3, 6, 2, 2, 6, 4, 8, 7, 6, 8, 1, 5, 1, 8, 2, 2, 4, 4, 5, 5, 6, 5, 5, 1, 7, 6, 6, 7, 3, 6, 4, 8, 7, 1, 1, 0, 3, 2, 4, 7, 8, 4, 8, 8, 7, 9, 4, 2, 8, 5, 4, 7, 3, 6, 4, 1, 5, 4, 1, 2, 1, 7, 2, 5, 3, 8, 3, 4, 8, 5, 2, 1, 2, 7, 7, 8, 5, 5, 8, 8, 2, 4, 2, 3, 7, 5, 2, 5, 7, 5, 2, 6, 1, 2, 7, 6, 3, 6, 2, 8, 7, 1, 5, 4, 5, 8, 2, 5, 3, 5, 6, 4, 5, 1, 3, 6, 8, 5, 4, 7, 4, 5, 8, 1, 7, 3, 8, 5, 6, 1, 2, 1, 3, 1, 2, 7, 8, 7, 5, 2, 5, 1, 5, 7, 2, 4, 7, 5, 2, 6, 0, 7, 1, 7, 4, 9, 6, 3, 3, 5, 1, 8, 3, 3, 1, 1, 2, 3, 5, 2, 4, 3, 1, 2, 8, 1, 4, 1, 4, 7, 5, 3, 9, 2, 5, 4, 8, 5, 2, 3, 3, 4, 3, 7, 6, 9, 2, 1, 2, 8, 3, 8, 3, 3, 8, 7, 6, 1, 7, 7, 3, 2, 6, 3, 4, 9, 6, 7, 1, 1, 2, 1, 3, 8, 2, 7, 2, 3, 5, 2, 5, 1, 6, 2, 8, 6, 6, 3, 2, 6, 6, 1, 5, 5, 3, 2, 2, 6, 3, 5, 2, 7, 6, 2, 6, 6, 7, 1, 2, 3, 2, 4, 0, 8, 7, 3, 2, 7, 1, 2, 3, 8, 2, 3, 1, 2, 8, 6, 0, 8, 5, 7, 9, 7, 3, 1, 7, 7, 2, 2, 1, 5, 1, 5, 1, 7, 7, 5, 5, 8, 5, 7, 3, 5, 8, 7, 7, 7, 4, 4, 5, 3, 7, 7, 4, 1, 5, 0, 8, 5, 6, 3, 2, 2, 6, 5, 7, 7, 8, 1, 2, 7, 3, 3, 7, 1, 7, 3, 1, 3, 1, 5, 3, 2, 4, 1, 2, 1, 7, 8, 5, 5, 7, 7, 1, 1, 4, 8, 3, 8, 1, 3, 3, 7, 3, 5, 1, 2, 5, 7, 5, 1, 5, 2, 7, 0, 5, 2, 2, 5, 6, 8, 1, 2, 6, 5, 7, 7, 2, 6, 4, 1, 4, 3, 6, 4, 4, 7, 5, 6, 3, 1, 6, 7, 3, 1, 2, 8, 1, 3, 6, 7, 7, 8, 3, 5, 8, 3, 3, 7, 4, 7, 8, 5, 3, 4, 7, 5, 0, 0, 4, 2, 1, 2, 7, 5, 6, 1, 2, 1, 1, 7, 2, 6, 7, 4, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "#Specifying the directory name, image size, and no of channels (1 for grayscale)\n",
    "src_filepath_pattern = dirname\n",
    "dest_filepath = dirname+'Assignmenttesth5'\n",
    "n_px = 64\n",
    "n_channels = 1\n",
    "\n",
    "convert_images_to_data_in_h5_file(src_filepath_pattern, dest_filepath, n_px, n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The below section was run in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install pillow\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('/content/drive/My Drive/Speech Assignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the h5 datafiles\n",
    "def load_dataset(prefix, filelimit):\n",
    "    \n",
    "    lmd_tic = time.time()\n",
    "    \n",
    "    X_full_dataset = []\n",
    "    Y_full_dataset = []\n",
    "    filename_prefix = prefix\n",
    "    \n",
    "    for i in range(1,filelimit):\n",
    "        \n",
    "        filename = filename_prefix + str(i) + \".h5\"\n",
    "        with h5py.File(filename, \"r\") as f:\n",
    "    \n",
    "            X_full_dataset.append(f[\"input_data\"][:])\n",
    "            Y_full_dataset.append(f[\"input_labels\"][:])\n",
    "\n",
    "    lmd_toc = time.time()\n",
    "    print('Time taken to load the data set is', ((lmd_toc-lmd_tic) * 1000), 'ms')\n",
    "    \n",
    "    return X_full_dataset, Y_full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the datasets\n",
    "X_train_dataset, Y_train_dataset = load_dataset('Assignmenttrainh5', 16)\n",
    "X_val_dataset, Y_val_dataset = load_dataset('AssignmentAssignmentvalh5', 3)\n",
    "X_test_dataset, Y_test_dataset = load_dataset('AssignmentAssignmenttesth5', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatting the dataset from the H5 File\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "#Reshaping and encoding the datasets\n",
    "\n",
    "#Training Set\n",
    "X_train = np.vstack(X_train_dataset)\n",
    "Y_train = np.hstack(Y_train_dataset)\n",
    "\n",
    "Y_train = Y_train.reshape(-1,1)\n",
    "enc.fit(Y_train)\n",
    "Y_train = enc.transform(Y_train)\n",
    "Y_train = Y_train.todense()\n",
    "\n",
    "#Validation Set\n",
    "X_val = np.vstack(X_val_dataset)\n",
    "Y_val = np.vstack(Y_val_dataset)\n",
    "\n",
    "Y_val = Y_val.reshape(-1,1)\n",
    "enc.fit(Y_val)\n",
    "Y_val = enc.transform(Y_val)\n",
    "Y_val = Y_val.todense()\n",
    "\n",
    "#Test Set\n",
    "X_test = np.vstack(X_test_dataset)\n",
    "Y_test = np.vstack(Y_test_dataset)\n",
    "\n",
    "Y_test = Y_test.reshape(-1,1)\n",
    "enc.fit(Y_test)\n",
    "Y_test = enc.transform(Y_test)\n",
    "Y_test = Y_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity checking types/shapes of vectors we're passing to CNN\n",
    "print(\"Training Set\")\n",
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "print(type(Y_train))\n",
    "print(Y_train.shape)\n",
    "print(\"---------------------------\")\n",
    "print(\"Validation Set\")\n",
    "print(type(X_val))\n",
    "print(X_val.shape)\n",
    "print(type(Y_val))\n",
    "print(Y_val.shape)\n",
    "print(\"---------------------------\")\n",
    "print(\"Test Set\")\n",
    "print(type(X_test))\n",
    "print(X_test.shape)\n",
    "print(type(Y_test))\n",
    "print(Y_test.shape)\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras import regularizers, optimizers, models\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 64\n",
    "img_width = 64\n",
    "\n",
    "#Define CNN Model\n",
    "input_shape = (img_height, img_width, 1)\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "nb_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST MODEL TRAINING SECTION\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "#Compile Model\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "\n",
    "#Train and Test The Model\n",
    "history_mnist = model.fit(\n",
    "        x = X_train.reshape(X_train.shape[0], img_height, img_width, 1), y = Y_train,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=40,\n",
    "        validation_data = (X_val.reshape(X_val.shape[0], img_height, img_width, 1), Y_val),\n",
    "        validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model to h5 file\n",
    "model.save(\"mnist_model_ver2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model and test\n",
    "mnist_model = models.load_model('mnist_model_ver2.h5')\n",
    "mnist_model.summary()\n",
    "\n",
    "loss,acc = mnist_model.evaluate(X_test.reshape(X_test.shape[0], img_height, img_width, 1),  Y_test, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot accuracy vs val_accuracy\n",
    "\n",
    "plt.plot(history_mnist.history['accuracy'])\n",
    "plt.plot(history_mnist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define CNN Model\n",
    "model2 = Sequential()\n",
    "input_shape = (img_height, img_width, 1)\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "nb_epochs = 20\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model2.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#Compile Model\n",
    "model2.compile(optimizers.adam(),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "print(model2.summary())\n",
    "\n",
    "#Train and Test The Model\n",
    "cnn_model_history = model2.fit(\n",
    "        x = X_train.reshape(X_train.shape[0], img_height, img_width, 1), y = Y_train,\n",
    "        batch_size = 20,\n",
    "        epochs=30,\n",
    "        verbose = 1,\n",
    "        validation_data = (X_val.reshape(X_val.shape[0], img_height, img_width, 1), Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model to file\n",
    "model2.save(\"cnn_model_with_adam_ver2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN model load and evaluation\n",
    "cnn_model = models.load_model('cnn_model_with_adam_ver2.h5')\n",
    "cnn_model.summary()\n",
    "\n",
    "loss,acc = cnn_model.evaluate(X_test.reshape(X_test.shape[0], img_height, img_width, 1),  Y_test, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot accuracy vs val_accuracy\n",
    "\n",
    "plt.plot(cnn_model_history.history['accuracy'])\n",
    "plt.plot(cnn_model_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define CNN Model\n",
    "model3 = Sequential()\n",
    "input_shape = (img_height, img_width, 1)\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "nb_epochs = 20\n",
    "\n",
    "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#Compile Model\n",
    "model3.compile(optimizers.adam(),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "print(model3.summary())\n",
    "\n",
    "#Train and Test The Model\n",
    "history = model3.fit(\n",
    "        x = X_train.reshape(X_train.shape[0], img_height, img_width, 1), y = Y_train,\n",
    "        batch_size = 32,\n",
    "        epochs=100,\n",
    "        verbose = 1,\n",
    "        validation_data = (X_val.reshape(X_val.shape[0], img_height, img_width, 1), Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving model to disk\n",
    "model3.save(\"cnn_model_batchnorm_ver2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and evaluation\n",
    "cnn_model = models.load_model(\"cnn_model_batchnorm_ver2.h5\")\n",
    "cnn_model.summary()\n",
    "\n",
    "loss,acc = cnn_model.evaluate(X_test.reshape(X_test.shape[0], img_height, img_width, 1),  Y_test, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accuracy versus Validation Accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
